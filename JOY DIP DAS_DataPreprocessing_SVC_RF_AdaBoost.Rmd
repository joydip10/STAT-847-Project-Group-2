---
title: "randomforest"
author: "Joy Dip Das"
date: "2023-12-11"
output: pdf_document
---



## Loading the titanic dataset from the folder- Project under dataset subfolder

```{r}
data <- read.csv("dataset\\titanic.csv")
test <- read.csv("dataset\\data\\test.csv")
```

```{r}
data$Embarked
```


```{r}
names(data)
dim(data)
```
### Explanation for the column names of the titanic dataset

\textbf{PassengerID}: A unique identifier for each passenger.

\textbf{Survived}: This binary variable indicates whether a passenger survived (1) or did not survive (0) the Titanic disaster. It is the target variable for predictive modeling.

\textbf{Pclass (Passenger Class)}: This represents the class of the passenger's ticket and, by extension, their socio-economic status. It has three possible values: 1st class, 2nd class, and 3rd class.

\textbf{Name}: The name of the passenger.

\textbf{Sex}: The gender of the passenger, which is either "male" or "female."

\textbf{Age}: The age of the passenger. Some entries may be missing.

\textbf{SibSp}: The number of siblings or spouses that the passenger had aboard the Titanic.

\textbf{Parch}: The number of parents or children that the passenger had aboard the Titanic.

\textbf{Ticket}: The ticket number.

\textbf{Fare}: The fare the passenger paid for the ticket.

\textbf{Cabin}: The cabin number of the passenger. This feature may have a lot of missing values.

\textbf{Embarked}: The port at which the passenger boarded the Titanic. It can take one of three values: "C" (Cherbourg), "Q" (Queenstown), or "S" (Southampton).



## Summary Statistics

```{r}
summary(data)
```

## Structure of the dataset

```{r}
str(data)
unique(data$Embarked)
```

## handling missing values


### Count null values 

```{r}
colSums(is.na(data))

colSums(is.na(test))
```

'Age' has 177 missing values

### Imputing all missing age values

```{r}
data$Age<-ifelse(is.na(data$Age), mean(data$Age, na.rm = TRUE), data$Age)
test$Age<-ifelse(is.na(test$Age), mean(test$Age, na.rm = TRUE), test$Age)
test$Fare<-ifelse(is.na(test$Fare), mean(test$Fare, na.rm = TRUE), test$Fare)
```

### Verifying that all missing values are handled

```{r}
colSums(is.na(data))
```
Here, the missing values from Age column of the dataset has been removed successfully 

#### Outlier detection by Fare feature

```{r}
#z_scores <- scale(data$Fare)

#threshold <- 3

#outlier_indices <- which(abs(z_scores) > threshold)

#cleaned_data <- data[-outlier_indices, ]

#summary(cleaned_data)

#num_outliers_removed <- length(outlier_indices)
#cat("Number of outliers removed:", num_outliers_removed, "\n")

#data <- cleaned_data
#dim(data)
```

The "Fare" feature was used for outlier detection in the example provided because it is a continuous numeric variable that often exhibits a wide range of values. Outliers in the "Fare" feature can have a significant impact on statistical analyses and machine learning models.

The "Fare" feature typically has a wider range of values compared to many other features in the dataset. Some passengers may have paid significantly higher fares, and these high values can potentially be outliers. The "Fare" is associated with the passenger's ticket class or economic class. Different fare levels correspond to different levels of service and accommodation on the Titanic. Therefore, extreme values in the "Fare" variable could be indicative of passengers with unique circumstances or special accommodations.

## Data Visualization

### Bar plot for passenger class (Pclass)

```{r}
library(ggplot2)
```

```{r}
ggplot(data, aes(x = factor(Pclass))) +
  geom_bar(fill = "lightblue") +
  labs(title = "Passenger Class Distribution",
       x = "Passenger Class",
       y = "Count")
```

### Histogram for age

```{r}
ggplot(data, aes(x = Age)) +
  geom_histogram(fill = "lightgreen", bins = 20) +
  labs(title = "Age Distribution",
       x = "Age",
       y = "Count")
```


### Bar plot for Gender (Sex)

```{r}
ggplot(data, aes(x = Sex, fill = Sex)) +
  geom_bar() +
  labs(title = "Gender Distribution",
       x = "Gender",
       y = "Count") +
  scale_fill_manual(values = c("male" = "lightblue", "female" = "lightpink"))

```

### Bar plot for Survival

```{r}
ggplot(data, aes(x = factor(Survived))) +
  geom_bar(fill = "lightblue") +
  labs(title = "Survival Distribution",
       x = "Survived",
       y = "Count")

```

### Scatterplot for exploring the relationship between age and fare

```{r}
ggplot(data, aes(x = Age, y = Fare)) +
  geom_point() +
  labs(title = "Age vs. Fare",
       x = "Age",
       y = "Fare")

```

### Box plot to visualize fare distribution by passenger class

```{r}
ggplot(data, aes(x = factor(Pclass), y = Fare)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Fare Distribution by Passenger Class",
       x = "Passenger Class",
       y = "Fare")
```

### bar plot for Embarked port

```{r}
ggplot(data, aes(x = factor(Embarked))) +
  geom_bar(fill = "lightblue") +
  labs(title = "Port of Embarkation Distribution",
       x = "Port of Embarkation",
       y = "Count")

```


### barplot for exploring family size (SibSp + Parch)

```{r}
data$FamilySize <- data$SibSp + data$Parch
ggplot(data, aes(x = factor(FamilySize))) +
  geom_bar(fill = "lightblue") +
  labs(title = "Family Size Distribution",
       x = "Family Size",
       y = "Count")
```

### Correlation plot

```{r}
library(corrplot)
library(dplyr)
```

```{r}
numericVars <- select_if(data, is.numeric)
correlationMatrix <- cor(numericVars)
corrplot(correlationMatrix, method = "color", type = "lower", tl.col = "black", 
         diag = FALSE, addCoef.col = "black", number.cex = 0.7)
```

### Pairplot for selected variables- Age, Fare, Pclass, FamilySize

```{r}
select_vars <- c("Age", "Fare", "Pclass", "FamilySize")
pairs(data[select_vars])
```

## Data Transformation

### Encoding categorical variables

#### Encoding Sex variable into binary format- 0 for male and 1 for female

```{r}
data$Sex <- as.factor(ifelse(data$Sex == "female", 1, 0))
test$Sex <- as.factor(ifelse(test$Sex == "female", 1, 0))
```

#### Encoding the "Embarked" variable as a factor

```{r}
data$Embarked <- as.factor(data$Embarked)
test$Embarked <- as.factor(test$Embarked)
#embarked_mapping <- c("S" = 1, "C" = 2, "Q" = 3," "=4)
#data$Embarked <- embarked_mapping[data$Embarked]

```

```{r}
data$Embarked
```

#### Scale the "Age" and "Fare" variables to have a mean of 0 and standard deviation of 1 (Standardization)

```{r}
#data$Age <- scale(data$Age)
#data$Fare <- scale(data$Fare)
```


```{r}
names(data)
head(data)
```


### Basic analysis from Correlation plot

#### Survival by Gender (Survived vs Gender)


```{r}
ggplot(data, aes(x = Survived, fill = Sex)) +
  geom_bar() +
  labs(title = "Survival by Gender",
       x = "Survived",
       y = "Count") +
  scale_fill_manual(values = c("0" = "lightblue", "1" = "lightpink"))

```

#### Survival by Pclass

```{r}
ggplot(data, aes(x = factor(Pclass), fill = factor(Survived))) +
  geom_bar() +
  labs(title = "Survival by Passenger Class",
       x = "Passenger Class",
       y = "Count") +
  scale_fill_manual(values = c("0" = "lightblue", "1" = "lightpink"))

```

#### Survival by port Embarked

```{r}
ggplot(data, aes(x = factor(Embarked), fill = factor(Survived))) +
  geom_bar() +
  labs(title = "Survival by port embarked",
       x = "Port of Embarkation",
       y = "Count") +
  scale_fill_manual(values = c("0" = "lightblue", "1" = "lightpink"))
```



#### Survival vs Fare

```{r}
ggplot(data, aes(x = Fare, fill = factor(Survived))) +
  geom_density(alpha = 0.6) +
  labs(title = "Distribution of Fare by Survival",
       x = "Fare",
       y = "Density") +
  scale_fill_manual(values = c("0" = "lightblue", "1" = "lightpink"))
```

#### Train Test Split

```{r}
set.seed(1)
id <- sample(1:nrow(data), 0.8 * nrow(data))
train_data <- data[id, ]
train_data$Survived <- as.factor(train_data$Survived)
test_data <- data[-id, ]
```


#### Logistic regresssion


```{r}
library(glmnet)

features <- c("Pclass", "Sex", "Age", "SibSp","Parch", "Fare","Embarked")
target <- "Survived"

x <- train_data[,features]
y <- train_data$Survived

data <- cbind(x, Survived = y)

predictors <- paste(colnames(x), collapse = " + ")
formula <- as.formula(paste("Survived ~", predictors))

lr <- glm(formula, data = data, family = binomial)

summary(lr)
test_x <- test_data[,features]
lr_predictions <- predict(lr, newdata = test_x, type = "response")
lr_predictions <- ifelse(lr_predictions > 0.5, 1, 0)
test_y <- test_data$Survived
correct_predictions <- sum(lr_predictions == test_y)
lr_accuracy <- correct_predictions / length(test_y)
cat('Logistic Regression:', lr_accuracy,"\n")

```
```{r}
p <- predict(lr, newdata = test[,features], type = "response")
p <- ifelse(p > 0.5, 1, 0)
p
```



```{r}
features <- c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare","Embarked")
```


#### SVM with grid search

```{r}
library(e1071)
library(caret)

preProc <- preProcess(train_data[, features], method = c("center", "scale"))
train_data_scaled <- predict(preProc, train_data[, features])
test_data_scaled <- predict(preProc, test_data[, features])

tuneGrid <- expand.grid(C = c(0.1, 1, 100),
                        kernel = c("linear", "polynomial", "radial"))

best_accuracy <- 0
best_C <- NULL
best_kernel <- NULL

for (C in tuneGrid$C) {
  for (kernel in tuneGrid$kernel) {
    svm_model <- svm(train_data$Survived ~ ., data = train_data_scaled, kernel = kernel, cost = C)
    
    svm_predictions <- predict(svm_model, newdata = test_data_scaled)
    
    conf_matrix <- table(svm_predictions, test_data$Survived)
    accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
    
    if (accuracy > best_accuracy) {
      best_accuracy <- accuracy
      best_C <- C
      best_kernel <- kernel
    }
  }
}

final_svm_model <- svm(train_data$Survived ~ ., data = train_data_scaled, kernel = best_kernel, cost = best_C)

svm_predictions <- predict(final_svm_model, newdata = test_data_scaled)
Testdata<-test_data$Survived

confusion_matrix<-table(Actual= Testdata,Predicted= svm_predictions)
confusion_matrix

final_accuracy <- (confusion_matrix[1,1]+confusion_matrix[2,2])/sum(confusion_matrix[,])


CrossTable( test_data$Survived,svm_predictions,   ## help create good table but doesn't give                                                                      accuracy
            prop.chisq = FALSE, prop.t = FALSE,
            dnn = c( 'actual','predicted'))


cat("Best Hyperparameters:\n")
cat("C =", best_C, "\n")
cat("Kernel =", best_kernel, "\n")
cat("Final Accuracy of SVC =", final_accuracy, "\n")
Precision<-confusion_matrix[1,1]/sum(confusion_matrix[,1])
cat("Precision",Precision,"\n")
Recall<-confusion_matrix[1,1]/sum(confusion_matrix[1,])
cat("Recall",Recall,"\n")
F1<-(2*Precision*Recall)/(Precision+Recall)
cat("F1 score",F1,"\n")
```
```{r}
test_data_scaled
```
```{r}
test_data_scaled <- predict(preProc, test[, features])
test_data_scaled
```




#### RandomForest with grid search

```{r}
set.seed(100)
library(randomForest)
library(gmodels)

features <- c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare","Embarked", "Survived")
train_data <- train_data[, features]
test_data <- test_data[, features]

tuneGrid <- expand.grid(
  mtry = c(2,3,4),  # Number of features considered at each split
  ntree = c(50, 100, 200,400,500)  # Number of trees in the forest
)

#Age+Sex+Pclass+Embarked+Parch

best_mtry <- NULL
best_ntree <- NULL
best_accuracy <- 0

for (mtry in tuneGrid$mtry) {
  for (ntree in tuneGrid$ntree) {
    rf_model <- randomForest(Survived ~ Age+Sex+Pclass+Fare, data = train_data, mtry = mtry, ntree = ntree)
    
    rf_predictions <- predict(rf_model, newdata = test_data)
    
    conf_matrix <- table(rf_predictions, test_data$Survived)
    accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
    
    if (accuracy > best_accuracy) {
      best_accuracy <- accuracy
      best_mtry <- mtry
      best_ntree <- ntree
    }
  }
}

final_rf_model <- randomForest(Survived ~ ., data = train_data, mtry = 3, ntree = 400)
summary(final_rf_model)
rf_predictions <- predict(final_rf_model, newdata = test_data)

## checking predictor importance
importance(final_rf_model)
varImpPlot(final_rf_model)
## Named testdata for confusion matrix
Testdata<-test_data$Survived

confusion_matrix<-table(Actual= Testdata,Predicted= rf_predictions)
confusion_matrix

CrossTable( test_data$Survived,rf_predictions,   ## help create good table but doesn't give                                                                      accuracy
            prop.chisq = FALSE, prop.t = FALSE,
            dnn = c( 'actual','predicted'))

Accuracy<-(confusion_matrix[1,1]+confusion_matrix[2,2])/sum(confusion_matrix[,])
cat("Accuracy",Accuracy,"\n")
Precision<-confusion_matrix[1,1]/sum(confusion_matrix[,1])
cat("Precision",Precision,"\n")
Recall<-confusion_matrix[1,1]/sum(confusion_matrix[1,])
cat("Recall",Recall,"\n")
F1<-(2*Precision*Recall)/(Precision+Recall)
cat("F1 score",F1,"\n")
## Accuracy 
final_accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
final_accuracy




### checking diffrent predictor for accuracy increase or decrease 
final_rf_model <- randomForest(Survived ~ Pclass+Sex+Age+Fare+SibSp+Embarked+Parch, data = train_data, mtry = 3, ntree = 400)
rf_predictions <- predict(final_rf_model, newdata = test_data)
Testdata<-test_data$Survived
conf_matrix <- table(rf_predictions, Testdata)
#conf_matrix

final_accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
final_accuracy

cat("Best Hyperparameters:\n")
cat("mtry =", best_mtry, "\n")
cat("ntree =", best_ntree, "\n")
cat("Final Accuracy of Random Forest =", final_accuracy, "\n")
```

#### Ensembling 



```{r}
library(adabag)

f<- c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare","Embarked")
features <- c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare","Embarked", "Survived")
train_data <- train_data[, features]
test_data <- test_data[, features]


tuneGrid <- expand.grid(
  coeflearn = c("Freund", "Breiman", "Zhu"),  
  mfinal = c(50, 100, 200),  
  boos = TRUE
)

best_coeflearn <- NULL
best_mfinal <- NULL
best_accuracy <- 0

ensemble_models<-list(lr,final_svm_model)

for (coeflearn in tuneGrid$coeflearn) {
  for (mfinal in tuneGrid$mfinal) {
    adaboost_model <- boosting(
      Survived ~ .,
      data = train_data,
      coeflearn = coeflearn,
      mfinal = mfinal,
      boos = TRUE,
      control = rpart.control(cp = 0.01,minsplit = 3)
    )

    adaboost_predictions <- predict(adaboost_model, newdata = test_data[,f])

    conf_matrix <- table(adaboost_predictions$class, test_data$Survived)
    accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)

    if (accuracy > best_accuracy) {
      best_accuracy <- accuracy
      best_coeflearn <- coeflearn
      best_mfinal <- mfinal
    }
  }
}

final_adaboost_model <- boosting(
  Survived ~ .,
  data = train_data,
  coeflearn = best_coeflearn,
  mfinal = best_mfinal,
  boos = TRUE,
  control = rpart.control(cp = 0.01,minsplit = 3)
)

adaboost_predictions <- predict(final_adaboost_model, newdata = test_data[,f])

#conf_matrix <- table(adaboost_predictions$class, test_data$Survived)
#final_accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)

Testdata<-test_data$Survived

confusion_matrix<-table(Actual= Testdata,Predicted= adaboost_predictions$class)
confusion_matrix

final_accuracy <- (confusion_matrix[1,1]+confusion_matrix[2,2])/sum(confusion_matrix[,])


CrossTable( test_data$Survived,adaboost_predictions$class,   ## help create good table but doesn't give                                                                      accuracy
            prop.chisq = FALSE, prop.t = FALSE,
            dnn = c( 'actual','predicted'))



cat("Best Hyperparameters:\n")
cat("coeflearn =", best_coeflearn, "\n")
cat("mfinal =", best_mfinal, "\n")
cat("Final Accuracy of Ensemble model=", final_accuracy, "\n")
Precision<-confusion_matrix[1,1]/sum(confusion_matrix[,1])
cat("Precision",Precision,"\n")
Recall<-confusion_matrix[1,1]/sum(confusion_matrix[1,])
cat("Recall",Recall,"\n")
F1<-(2*Precision*Recall)/(Precision+Recall)
cat("F1 score",F1,"\n")

``` 



